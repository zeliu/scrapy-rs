# Mock Server for Scrapy-RS Benchmarking

This document explains how to use the Mock Server for benchmarking Scrapy and Scrapy-RS, eliminating the impact of network conditions and external websites on test results.

## Overview

The Mock Server is a simple HTTP server that simulates a website with multiple linked pages. It offers the following features:

- Configurable number of pages and links per page
- Configurable response delay
- Optional failure simulation
- robots.txt support
- Request logging and statistics

Using the Mock Server for benchmarking ensures reproducibility of test results and eliminates external factors (such as network latency and target website response times).

## Benefits of Mock Server

- **Controlled Environment**: Complete control over the crawl environment, avoiding requests to external websites
- **Consistency**: More consistent tests as the mock server provides predictable responses
- **Speed**: Faster execution since there's no dependency on external network I/O unpredictability
- **Accurate Statistics**: Precise knowledge of how many pages were crawled and items collected
- **Reproducibility**: Tests can be reproduced with identical results regardless of network conditions
- **Resource Usage Analysis**: Better isolation for measuring CPU and memory usage of crawlers
- **No External Impact**: Avoid impacting real websites with benchmark traffic

## Usage

### Basic Usage

To use the Mock Server for benchmarking, simply add the `--use-mock-server` flag when running the benchmark command:

```bash
cargo run -- run --use-mock-server --output-dir benchmark_results
```

This will start a Mock Server with default configuration (100 pages, 10 links per page) and use it for benchmarking.

### Custom Configuration

You can customize the Mock Server behavior with the following parameters:

- `--mock-server-port <PORT>`: Set the port the Mock Server listens on (default: 8000)
- `--mock-server-pages <COUNT>`: Set the number of pages generated by the Mock Server (default: 100)
- `--mock-server-links <COUNT>`: Set the number of links per page (default: 10)
- `--mock-server-delay <MS>`: Set response delay in milliseconds (default: 0)
- `--mock-server-failures`: Enable failure simulation
- `--mock-server-failure-rate <RATE>`: Set failure rate between 0.0 and 1.0 (default: 0.1)

Example:

```bash
cargo run -- run --use-mock-server \
    --mock-server-port 8080 \
    --mock-server-pages 50 \
    --mock-server-links 5 \
    --mock-server-delay 100 \
    --mock-server-failures \
    --mock-server-failure-rate 0.05 \
    --output-dir benchmark_results
```

This starts a Mock Server with 50 pages, 5 links per page, 100ms response delay, and a 5% chance of simulating request failures.

### Testing Only Scrapy

To benchmark only the Scrapy implementation against the mock server:

```bash
cargo run -- run --use-mock-server --mock-server-pages 20 --mock-server-links 5 --output-dir benchmark_results --only-scrapy
```

This allows you to isolate and test Scrapy performance with the mock server.

## Output Results

The benchmark results are saved in the specified output directory, including:

- Crawled items (JSON format)
- Benchmark results (CSV format)
- HTML report (comparing Scrapy and Scrapy-RS performance)

The CSV files contain detailed metrics including:
- Framework name and version
- Start and end time
- Duration
- Request and response counts
- Item count
- Error count
- Requests per second
- Items per second
- Memory usage
- CPU usage

## Implementation Details

The mock server creates a controlled web environment with the following characteristics:

1. **Page Structure**: Each page contains a configurable number of links to other pages within the mock site
2. **Content Generation**: Pages include predictable content patterns for consistent extraction
3. **Link Graph**: Pages are interconnected in a directed graph pattern to simulate a real website
4. **Depth Limitation**: The default maximum crawl depth is 2, but this can be adjusted

## Best Practices

1. **Comparative Testing**: Always test both Scrapy and Scrapy-RS when using the Mock Server for direct comparison
2. **Consistent Environment**: Run benchmarks on the same machine with similar system loads for comparable results
3. **Multiple Runs**: Conduct multiple benchmark runs and average the results for more reliable comparisons
4. **Vary Parameters**: Test with different configurations to understand performance characteristics under various scenarios
5. **Isolate Variables**: When comparing specific aspects, change only one parameter at a time

## Example Scenarios

### Basic Comparison

```bash
cargo run -- run --use-mock-server --output-dir results
```

### High Concurrency Test

```bash
cargo run -- run --use-mock-server --concurrent-requests 50 --output-dir results_high_concurrency
```

### Latency Test

```bash
cargo run -- run --use-mock-server --mock-server-delay 200 --output-dir results_with_delay
```

### Error Handling Test

```bash
cargo run -- run --use-mock-server --mock-server-failures --mock-server-failure-rate 0.2 --output-dir results_with_errors
```

### Large Site Test

```bash
cargo run -- run --use-mock-server --mock-server-pages 1000 --page-limit 1000 --output-dir results_large_site
```

## Troubleshooting

If you encounter issues with the mock server benchmarks:

1. **Check Port Availability**: Ensure the specified port is not already in use
2. **Memory Constraints**: For large page counts, ensure your system has sufficient memory
3. **JSON Serialization**: If experiencing issues with datetime serialization in stats, verify that the custom DateTimeEncoder is properly implemented
4. **Spider Implementation**: Ensure your spider correctly uses the mock server URLs when the --use-mock-server flag is set

## Notes

1. The Mock Server is fully supported for both Scrapy and Scrapy-RS benchmarking
2. Benchmark results will vary based on system load and hardware specifications
3. Using `--use-mock-server` will override URLs specified via `--urls` 